<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<title>OpenANN: OpenANN::MBSGD Class Reference</title>

<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link href="doxygen.css" rel="stylesheet" type="text/css" />

<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>

</head>
<body>
<div id="top"><!-- do not remove this div! -->


<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  
  <td id="projectlogo"><img alt="Logo" src="openann-logo-small.png"/></td>
  
  
  <td style="padding-left: 0.5em;">
   <div id="projectname">OpenANN
   &#160;<span id="projectnumber">1.0.0</span>
   </div>
   <div id="projectbrief">An open source library for artificial neural networks.</div>
  </td>
  
  
  
 </tr>
 </tbody>
</table>
</div>

<!-- Generated by Doxygen 1.7.6.1 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="dynsections.js"></script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li class="current"><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li><a href="dirs.html"><span>Directories</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="annotated.html"><span>List</span></a></li>
      <li><a href="classes.html"><span>Index</span></a></li>
      <li><a href="inherits.html"><span>Inheritance</span></a></li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Classes</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Namespaces</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Files</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(4)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(5)"><span class="SelectionMark">&#160;</span>Variables</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(6)"><span class="SelectionMark">&#160;</span>Typedefs</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(7)"><span class="SelectionMark">&#160;</span>Enumerations</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(8)"><span class="SelectionMark">&#160;</span>Enumerator</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(9)"><span class="SelectionMark">&#160;</span>Friends</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(10)"><span class="SelectionMark">&#160;</span>Defines</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

  <div id="nav-path" class="navpath">
    <ul>
      <li class="navelem"><a class="el" href="namespaceOpenANN.html">OpenANN</a>      </li>
      <li class="navelem"><a class="el" href="classOpenANN_1_1MBSGD.html">MBSGD</a>      </li>
    </ul>
  </div>
</div>
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a>  </div>
  <div class="headertitle">
<div class="title">OpenANN::MBSGD Class Reference</div>  </div>
</div><!--header-->
<div class="contents">
<!-- doxytag: class="OpenANN::MBSGD" --><!-- doxytag: inherits="OpenANN::Optimizer" -->
<p>Mini-batch stochastic gradient descent.  
 <a href="classOpenANN_1_1MBSGD.html#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="MBSGD_8h_source.html">MBSGD.h</a>&gt;</code></p>
<div id="dynsection-0" onclick="return toggleVisibility(this)" class="dynheader closed" style="cursor:pointer;">
  <img id="dynsection-0-trigger" src="closed.png" alt="+"/> Inheritance diagram for OpenANN::MBSGD:</div>
<div id="dynsection-0-summary" class="dynsummary" style="display:block;">
</div>
<div id="dynsection-0-content" class="dyncontent" style="display:none;">
<div class="center"><img src="classOpenANN_1_1MBSGD__inherit__graph.png" border="0" usemap="#OpenANN_1_1MBSGD_inherit__map" alt="Inheritance graph"/></div>
<map name="OpenANN_1_1MBSGD_inherit__map" id="OpenANN_1_1MBSGD_inherit__map">
<area shape="rect" id="node2" href="classOpenANN_1_1Optimizer.html" title="The common interface of all optimization algorithms." alt="" coords="5,5,152,195"/></map>
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>

<p><a href="classOpenANN_1_1MBSGD-members.html">List of all members.</a></p>
<table class="memberdecls">
<tr><td colspan="2"><h2><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classOpenANN_1_1MBSGD.html#af1f08ce49b11d328dce5a8be043f27f2">MBSGD</a> (double learningRate=0.01, double momentum=0.5, int batchSize=10, double learningRateDecay=1.0, double minimalLearningRate=0.0, double momentumGain=0.0, double maximalMomentum=1.0, double minGain=1.0, double maxGain=1.0)</td></tr>
<tr><td class="mdescLeft">&#160;</td><td class="mdescRight">Create mini-batch stochastic gradient descent optimizer.  <a href="#af1f08ce49b11d328dce5a8be043f27f2"></a><br/></td></tr>
<tr><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classOpenANN_1_1MBSGD.html#aa0e4135fb34527af86d866dffb831872">~MBSGD</a> ()</td></tr>
<tr><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classOpenANN_1_1MBSGD.html#a2a0da36dbbd0b724b064c68337454c8b">setOptimizable</a> (<a class="el" href="classOpenANN_1_1Optimizable.html">Optimizable</a> &amp;opt)</td></tr>
<tr><td class="mdescLeft">&#160;</td><td class="mdescRight">Pass the objective function.  <a href="#a2a0da36dbbd0b724b064c68337454c8b"></a><br/></td></tr>
<tr><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classOpenANN_1_1MBSGD.html#abd7daf44e185e58271f008e1daecb6bd">setStopCriteria</a> (const <a class="el" href="classOpenANN_1_1StoppingCriteria.html">StoppingCriteria</a> &amp;stop)</td></tr>
<tr><td class="mdescLeft">&#160;</td><td class="mdescRight">Pass the stop criteria.  <a href="#abd7daf44e185e58271f008e1daecb6bd"></a><br/></td></tr>
<tr><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classOpenANN_1_1MBSGD.html#aa605599beec817abd81bdbfd38ab06bd">optimize</a> ()</td></tr>
<tr><td class="mdescLeft">&#160;</td><td class="mdescRight">Optimize until the optimization meets the stop criteria.  <a href="#aa605599beec817abd81bdbfd38ab06bd"></a><br/></td></tr>
<tr><td class="memItemLeft" align="right" valign="top">virtual bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classOpenANN_1_1MBSGD.html#a78274c3bf331e37213512282aea3878c">step</a> ()</td></tr>
<tr><td class="mdescLeft">&#160;</td><td class="mdescRight">Execute one optimization step.  <a href="#a78274c3bf331e37213512282aea3878c"></a><br/></td></tr>
<tr><td class="memItemLeft" align="right" valign="top">virtual Eigen::VectorXd&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classOpenANN_1_1MBSGD.html#af4a9fc08de6e6d1a7d73782fc1bf10b4">result</a> ()</td></tr>
<tr><td class="mdescLeft">&#160;</td><td class="mdescRight">Determine the best result.  <a href="#af4a9fc08de6e6d1a7d73782fc1bf10b4"></a><br/></td></tr>
<tr><td class="memItemLeft" align="right" valign="top">virtual std::string&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classOpenANN_1_1MBSGD.html#af986194f6d3719467f9dd43b120afbd8">name</a> ()</td></tr>
<tr><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the name of the optimization algorithm.  <a href="#af986194f6d3719467f9dd43b120afbd8"></a><br/></td></tr>
</table>
<hr/><a name="details" id="details"></a><h2>Detailed Description</h2>
<div class="textblock"><p>Mini-batch stochastic gradient descent. </p>
<p>This implementation of gradient descent has some modifications:</p>
<ul>
<li>it is stochastic, we update the weights with a randomly chosen subset of the training set to escape local minima and thus increase the generalization capabilities</li>
<li>we use a momentum to smooth the search direction</li>
<li>each weight has an adaptive learning rate</li>
<li>we can decrease the learning rate during optimization</li>
<li>we can increase the momentum during optimization</li>
<li>we can regularize the weights, so that the generalization will be better</li>
</ul>
<p>A good introduction to optimization with <a class="el" href="classOpenANN_1_1MBSGD.html" title="Mini-batch stochastic gradient descent.">MBSGD</a> can be found in Geoff Hinton's Coursera course "Neural Networks for Machine Learning". A detailed description of this implementation follows.</p>
<p>When the batch size equals 1, the algorithms degenerates to stochastic gradient descent. When it equals the training set size, the algorithm is like batch gradient descent.</p>
<p>Standard mini-batch stochastic gradient descent updates the weight vector w in step t through</p>
<p><img class="formulaInl" alt="$ w^t = w^{t-1} - \frac{\alpha}{|B_t|} \sum_{n \in B_t} \nabla E_n(w) $" src="form_45.png"/></p>
<p>or</p>
<p><img class="formulaInl" alt="$ \Delta w^t = - \frac{\alpha}{|B_t|} \sum_{n \in B_t} \nabla E_n(w), \quad w^t = w^{t-1} + \Delta w^t, $" src="form_46.png"/></p>
<p>where <img class="formulaInl" alt="$ \alpha $" src="form_25.png"/> is the learning rate and <img class="formulaInl" alt="$ B_t $" src="form_47.png"/> is the set of indices of the t-th mini-batch, which is drawn randomly. The random order of gradients prevents us from getting stuck in local minima. This is an advantage over batch gradient descent. However, we must not make the batch size too small. A bigger batch size makes the optimization more robust against noise of the training set. A reasonable batch size is between 10 and 100. The learning rate has to be within [0, 1). High learning rates can result in divergence, i.e. the error increases. Too low learning rates might make learning too slow, i.e. the number of epochs required to find an optimum might be infeasibe. A reasonable value for :math:`\alpha` is usually within [1e-5, 0.1].</p>
<p>A momentum can increase the optimization stability. In this case, the update rule is</p>
<p><img class="formulaInl" alt="$ \Delta w^t = \eta \Delta w^{t-1} - \frac{\alpha}{|B_t|} \sum_{n \in B_t} \nabla E_n(w), \quad w^t = w^{t-1} + \Delta w^t, $" src="form_48.png"/></p>
<p>where <img class="formulaInl" alt="$ \eta $" src="form_49.png"/> is called momentum and must lie in [0, 1). The momentum term incorporates past gradients with exponentially decaying influence. This reduces changes of the search direction. An intuitive explanation of this update rule is: we regard w as the position of a ball that is rolling down a hill. The gradient represents its acceleration and the acceleration modifies its momentum.</p>
<p>Another trick is using different learning rates for each weight. For each weight <img class="formulaInl" alt="$ w_{ji} $" src="form_50.png"/> we can introduce a gain <img class="formulaInl" alt="$ g_{ji} $" src="form_51.png"/> which will be multiplied with the learning rate so that we obtain an update rule for each weight</p>
<p><img class="formulaInl" alt="$ \Delta w_{ji}^t = \eta \Delta w_{ji}^{t-1} - \frac{\alpha g_{ji}^{t-1}}{|B_t|} \sum_{n \in B_t} \nabla E_n(w_{ji}), \quad w_{ji}^t = w_{ji}^{t-1} + \Delta w_{ji}^t, $" src="form_52.png"/></p>
<p>where <img class="formulaInl" alt="$ g_{ji}^0 = 1 $" src="form_53.png"/> and <img class="formulaInl" alt="$ g_{ji} $" src="form_51.png"/> will be increased by 0.05 if <img class="formulaInl" alt="$ \Delta w_{ji}^t \Delta w_{ji}^{t-1} \geq 0 $" src="form_54.png"/>, i.e. the sign of the search direction did not change and <img class="formulaInl" alt="$ g_{ji} $" src="form_51.png"/> will be multiplied by 0.95 otherwise. We set a minimum and a maximum value for each gain. Usually these are 0.1 and 10 or 0.001 and 100 respectively.</p>
<p>During optimization it often makes sense to start with a more global search, i.e. with a high learning rate and decrease the learning rate as we approach the minimum so that we obtain an update rule for the learning rate:</p>
<p><img class="formulaInl" alt="$ \alpha^t = max(\alpha_{decay} \alpha^{t-1}, \alpha_{min}). $" src="form_55.png"/></p>
<p>In addition, we can allow the optimizer to change the search direction more often at the beginning of the optimization and reduce this possibility at the end. To do this, we can start with a low momentum and increase it over time until we reach a maximum:</p>
<p><img class="formulaInl" alt="$ \eta^t = min(\eta^{t-1} + \eta_{inc}, \eta_{max}). $" src="form_56.png"/></p>
<p>To avoid overfitting it is sometimes helpful to add a penalty on the squared weight norm, i.e. we substract</p>
<p><img class="formulaInl" alt="$ \alpha \gamma w^{t-1} $" src="form_57.png"/></p>
<p>from the weight vector in each update. </p>
</div><hr/><h2>Constructor &amp; Destructor Documentation</h2>
<a class="anchor" id="af1f08ce49b11d328dce5a8be043f27f2"></a><!-- doxytag: member="OpenANN::MBSGD::MBSGD" ref="af1f08ce49b11d328dce5a8be043f27f2" args="(double learningRate=0.01, double momentum=0.5, int batchSize=10, double learningRateDecay=1.0, double minimalLearningRate=0.0, double momentumGain=0.0, double maximalMomentum=1.0, double minGain=1.0, double maxGain=1.0)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classOpenANN_1_1MBSGD.html#af1f08ce49b11d328dce5a8be043f27f2">OpenANN::MBSGD::MBSGD</a> </td>
          <td>(</td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>learningRate</em> = <code>0.01</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>momentum</em> = <code>0.5</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>batchSize</em> = <code>10</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>learningRateDecay</em> = <code>1.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>minimalLearningRate</em> = <code>0.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>momentumGain</em> = <code>0.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>maximalMomentum</em> = <code>1.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>minGain</em> = <code>1.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>maxGain</em> = <code>1.0</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>Create mini-batch stochastic gradient descent optimizer. </p>
<dl class="params"><dt><b>Parameters:</b></dt><dd>
  <table class="params">
    <tr><td class="paramname">learningRate</td><td>learning rate (usually called alpha); range: (0, 1] </td></tr>
    <tr><td class="paramname">momentum</td><td>momentum coefficient (usually called eta); range: [0, 1) </td></tr>
    <tr><td class="paramname">batchSize</td><td>size of the mini-batches; range: [1, N], where N is the size of the training set </td></tr>
    <tr><td class="paramname">learningRateDecay</td><td>will be multiplied with the learning rate after each weight update; range: (0, 1] </td></tr>
    <tr><td class="paramname">minimalLearningRate</td><td>minimum value for the learning rate; range: [0, 1] </td></tr>
    <tr><td class="paramname">momentumGain</td><td>will be added to the momentum after each weight update; range: [0, 1) </td></tr>
    <tr><td class="paramname">maximalMomentum</td><td>maximum value for the momentum; range [0, 1] </td></tr>
    <tr><td class="paramname">minGain</td><td>minimum factor for individual learning rates </td></tr>
    <tr><td class="paramname">maxGain</td><td>maximum factor for individual learning rates </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="aa0e4135fb34527af86d866dffb831872"></a><!-- doxytag: member="OpenANN::MBSGD::~MBSGD" ref="aa0e4135fb34527af86d866dffb831872" args="()" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classOpenANN_1_1MBSGD.html#aa0e4135fb34527af86d866dffb831872">OpenANN::MBSGD::~MBSGD</a> </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

</div>
</div>
<hr/><h2>Member Function Documentation</h2>
<a class="anchor" id="af986194f6d3719467f9dd43b120afbd8"></a><!-- doxytag: member="OpenANN::MBSGD::name" ref="af986194f6d3719467f9dd43b120afbd8" args="()" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">virtual std::string <a class="el" href="classOpenANN_1_1MBSGD.html#af986194f6d3719467f9dd43b120afbd8">OpenANN::MBSGD::name</a> </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td><code> [virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>Get the name of the optimization algorithm. </p>
<dl class="return"><dt><b>Returns:</b></dt><dd>name of the optimization algorithm </dd></dl>

<p>Implements <a class="el" href="classOpenANN_1_1Optimizer.html#ae622b25a58b293c9e84b255289bf0d7d">OpenANN::Optimizer</a>.</p>

</div>
</div>
<a class="anchor" id="aa605599beec817abd81bdbfd38ab06bd"></a><!-- doxytag: member="OpenANN::MBSGD::optimize" ref="aa605599beec817abd81bdbfd38ab06bd" args="()" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">virtual void <a class="el" href="classOpenANN_1_1MBSGD.html#aa605599beec817abd81bdbfd38ab06bd">OpenANN::MBSGD::optimize</a> </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td><code> [virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>Optimize until the optimization meets the stop criteria. </p>

<p>Implements <a class="el" href="classOpenANN_1_1Optimizer.html#a82dd1d0bb3174099076c5df98114c7bc">OpenANN::Optimizer</a>.</p>

</div>
</div>
<a class="anchor" id="af4a9fc08de6e6d1a7d73782fc1bf10b4"></a><!-- doxytag: member="OpenANN::MBSGD::result" ref="af4a9fc08de6e6d1a7d73782fc1bf10b4" args="()" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">virtual Eigen::VectorXd <a class="el" href="classOpenANN_1_1MBSGD.html#af4a9fc08de6e6d1a7d73782fc1bf10b4">OpenANN::MBSGD::result</a> </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td><code> [virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>Determine the best result. </p>
<dl class="return"><dt><b>Returns:</b></dt><dd>the best parameter the algorithm found </dd></dl>

<p>Implements <a class="el" href="classOpenANN_1_1Optimizer.html#aa1fe7b1a0ee5075465dd2fcab268d187">OpenANN::Optimizer</a>.</p>

</div>
</div>
<a class="anchor" id="a2a0da36dbbd0b724b064c68337454c8b"></a><!-- doxytag: member="OpenANN::MBSGD::setOptimizable" ref="a2a0da36dbbd0b724b064c68337454c8b" args="(Optimizable &amp;opt)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">virtual void <a class="el" href="classOpenANN_1_1MBSGD.html#a2a0da36dbbd0b724b064c68337454c8b">OpenANN::MBSGD::setOptimizable</a> </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classOpenANN_1_1Optimizable.html">Optimizable</a> &amp;&#160;</td>
          <td class="paramname"><em>optimizable</em></td><td>)</td>
          <td><code> [virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>Pass the objective function. </p>
<dl class="params"><dt><b>Parameters:</b></dt><dd>
  <table class="params">
    <tr><td class="paramname">optimizable</td><td>objective function, e. g. error function of an ANN </td></tr>
  </table>
  </dd>
</dl>

<p>Implements <a class="el" href="classOpenANN_1_1Optimizer.html#a6eb04ebef8105a1c7507cfd785b96a3c">OpenANN::Optimizer</a>.</p>

</div>
</div>
<a class="anchor" id="abd7daf44e185e58271f008e1daecb6bd"></a><!-- doxytag: member="OpenANN::MBSGD::setStopCriteria" ref="abd7daf44e185e58271f008e1daecb6bd" args="(const StoppingCriteria &amp;stop)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">virtual void <a class="el" href="classOpenANN_1_1MBSGD.html#abd7daf44e185e58271f008e1daecb6bd">OpenANN::MBSGD::setStopCriteria</a> </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classOpenANN_1_1StoppingCriteria.html">StoppingCriteria</a> &amp;&#160;</td>
          <td class="paramname"><em>sc</em></td><td>)</td>
          <td><code> [virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>Pass the stop criteria. </p>
<dl class="params"><dt><b>Parameters:</b></dt><dd>
  <table class="params">
    <tr><td class="paramname">sc</td><td>the parameters used to stop the optimization </td></tr>
  </table>
  </dd>
</dl>

<p>Implements <a class="el" href="classOpenANN_1_1Optimizer.html#a62ca350d18cf4cd88f6e600ea843f6a5">OpenANN::Optimizer</a>.</p>

</div>
</div>
<a class="anchor" id="a78274c3bf331e37213512282aea3878c"></a><!-- doxytag: member="OpenANN::MBSGD::step" ref="a78274c3bf331e37213512282aea3878c" args="()" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">virtual bool <a class="el" href="classOpenANN_1_1MBSGD.html#a78274c3bf331e37213512282aea3878c">OpenANN::MBSGD::step</a> </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td><code> [virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>Execute one optimization step. </p>

<p>Implements <a class="el" href="classOpenANN_1_1Optimizer.html#a843fc2d70cfd87dbd0212192324226cf">OpenANN::Optimizer</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>OpenANN/optimization/<a class="el" href="MBSGD_8h_source.html">MBSGD.h</a></li>
</ul>
</div><!-- contents -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Classes</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Namespaces</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Files</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(4)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(5)"><span class="SelectionMark">&#160;</span>Variables</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(6)"><span class="SelectionMark">&#160;</span>Typedefs</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(7)"><span class="SelectionMark">&#160;</span>Enumerations</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(8)"><span class="SelectionMark">&#160;</span>Enumerator</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(9)"><span class="SelectionMark">&#160;</span>Friends</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(10)"><span class="SelectionMark">&#160;</span>Defines</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>



<hr class="footer"/><address class="footer"><small>
Generated on Fri Jun 21 2013 08:32:07 for OpenANN by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.7.6.1
</small></address>

</body>
</html>
